{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from statsmodels.formula.api import ols\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import explained_variance_score as evs\n",
    "\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_residuals(y, yhat, df):\n",
    "    sns.relplot(x=y, y=yhat, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "def regression_errors(actual, predicted):\n",
    "    '''\n",
    "    Takes in the actual and predicted values of y.\n",
    "    Returns Sum of Squared Errors (SSE).\n",
    "        Evaluated Sum of Squares (ESS),\n",
    "        Total Sum of Squares (TSS),\n",
    "        Mean Squared Error (MSE),\n",
    "        Root Mean Squared Error (RMSE)\n",
    "    '''\n",
    "    SSE = mse(actual, predicted) * len(actual)\n",
    "    ESS = sum((predicted - actual.mean()) ** 2)\n",
    "    TSS = ESS + SSE\n",
    "    MSE = mse(actual, predicted)\n",
    "    RMSE = sqrt(MSE)\n",
    "    \n",
    "    return SSE, ESS, TSS, MSE, RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_mean_errors(actual, predicted_baseline):\n",
    "    '''\n",
    "    Takes in the actual values for u and the predicted baseline values for y.\n",
    "    Returns the SSE, MSE, and RMSE for the baseline\n",
    "    '''\n",
    "    SSE_baseline = mse(actual, predicted_baseline) * len(actual)\n",
    "    MSE_baseline = mse(actual, predicted_baseline)\n",
    "    RMSE_baseline = sqrt(MSE_baseline)\n",
    "    \n",
    "    return SEE_baseline, MSE_baseline, RMSE_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bettter_than_baeline(RMSE, RMSE_baseline):\n",
    "    if RMSE < RMSE_baseline:\n",
    "        print('Model is better than baseline')\n",
    "    else:\n",
    "        print('Baseline is better, need to look into different model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_significance(model, actual, predicted):\n",
    "    '''\n",
    "    Takes in a model, the actual y values, and the predicted y values.\n",
    "    Calculates the significance of the model by comparing it's p-value to an\n",
    "    alpha of 0.05.\n",
    "    Prints out whether or not the model is significant.\n",
    "    Returns the Explained Variance of Squares.\n",
    "    '''\n",
    "    p = model.f_pvalue\n",
    "    alpha = 0.05\n",
    "    \n",
    "    EVS = evs(actual, predicted)\n",
    "    \n",
    "    if p < 0.05:\n",
    "        print(f'p: {p} is less than alpha: {alpha}, therefore our model is significant.')\n",
    "    else:\n",
    "        print(f'p: {p} is more than alpha: {alpha}, therefore our model is not significant.')\n",
    "    print('\\n')\n",
    "    print(f'EVS: {EVS}')\n",
    "    return evs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
